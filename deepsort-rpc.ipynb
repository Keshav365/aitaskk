{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":261498,"sourceType":"datasetVersion","datasetId":102034},{"sourceId":10732433,"sourceType":"datasetVersion","datasetId":6654197}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install deep_sort_realtime pycocotools\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:05.763595Z","iopub.execute_input":"2025-02-12T22:43:05.763861Z","iopub.status.idle":"2025-02-12T22:43:10.411282Z","shell.execute_reply.started":"2025-02-12T22:43:05.763831Z","shell.execute_reply":"2025-02-12T22:43:10.410509Z"}},"outputs":[{"name":"stdout","text":"Collecting deep_sort_realtime\n  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.8)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.13.1)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (4.10.0.84)\nRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->deep_sort_realtime) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->deep_sort_realtime) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->deep_sort_realtime) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->deep_sort_realtime) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->deep_sort_realtime) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->deep_sort_realtime) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->deep_sort_realtime) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->deep_sort_realtime) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->deep_sort_realtime) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->deep_sort_realtime) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->deep_sort_realtime) (2024.2.0)\nDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: deep_sort_realtime\nSuccessfully installed deep_sort_realtime-1.3.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport scipy.io\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:10.412251Z","iopub.execute_input":"2025-02-12T22:43:10.412581Z","iopub.status.idle":"2025-02-12T22:43:22.483293Z","shell.execute_reply.started":"2025-02-12T22:43:10.412540Z","shell.execute_reply":"2025-02-12T22:43:22.482677Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Enable Mixed Precision Training\nset_global_policy('mixed_float16')\n\n# Load Retail Product Checkout (RPC) Dataset\nDATASET_PATH = \"/kaggle/input/retail-product-checkout-dataset\"\nTRAIN_DIR = os.path.join(DATASET_PATH, \"train2019\")\nVAL_DIR = os.path.join(DATASET_PATH, \"val2019\")\nTEST_DIR = os.path.join(DATASET_PATH, \"test2019\")\nANNOTATIONS_TRAIN = os.path.join(DATASET_PATH, \"instances_train2019.json\")\nANNOTATIONS_VAL = os.path.join(DATASET_PATH, \"instances_val2019.json\")\nANNOTATIONS_TEST = os.path.join(DATASET_PATH, \"instances_test2019.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:22.484054Z","iopub.execute_input":"2025-02-12T22:43:22.484574Z","iopub.status.idle":"2025-02-12T22:43:22.489087Z","shell.execute_reply.started":"2025-02-12T22:43:22.484549Z","shell.execute_reply":"2025-02-12T22:43:22.488151Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load COCO Annotations\ndef load_coco_annotations(annotation_file):\n    coco = COCO(annotation_file)\n    return coco\n\ncoco_train = load_coco_annotations(ANNOTATIONS_TRAIN)\ncoco_val = load_coco_annotations(ANNOTATIONS_VAL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:22.491407Z","iopub.execute_input":"2025-02-12T22:43:22.491717Z","iopub.status.idle":"2025-02-12T22:43:24.375367Z","shell.execute_reply.started":"2025-02-12T22:43:22.491682Z","shell.execute_reply":"2025-02-12T22:43:24.374629Z"}},"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.82s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.93s)\ncreating index...\nindex created!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Custom Data Generator for COCO Dataset\nclass CocoDataGenerator(Sequence):\n    def __init__(self, coco, img_dir, batch_size=32, img_size=(224, 224), shuffle=True):\n        self.coco = coco\n        self.img_dir = img_dir\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.shuffle = shuffle\n        self.image_ids = list(self.coco.imgs.keys())\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.image_ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        start_idx = index * self.batch_size\n        end_idx = min((index + 1) * self.batch_size, len(self.image_ids))\n        indexes = self.indexes[start_idx:end_idx]\n        \n        if len(indexes) == 0:\n            return np.empty((0, *self.img_size, 3)), np.empty((0, NUM_CLASSES))\n        \n        image_ids_temp = [self.image_ids[k] for k in indexes]\n        X, y = self.__data_generation(image_ids_temp)\n        return X, y\n\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.image_ids))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, image_ids_temp):\n        X = np.empty((self.batch_size, *self.img_size, 3))\n        y = np.empty((self.batch_size, 1), dtype=int)\n\n        for i, img_id in enumerate(image_ids_temp):\n            img_info = self.coco.imgs[img_id]\n            img_path = os.path.join(self.img_dir, img_info['file_name'])\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, self.img_size)\n            img = img / 255.0\n            X[i,] = img\n\n            ann_ids = self.coco.getAnnIds(imgIds=img_id)\n            anns = self.coco.loadAnns(ann_ids)\n            category_id = anns[0]['category_id'] if anns else 0\n\n            # Ensure category_id is within bounds\n            category_id = min(category_id, len(self.coco.cats) - 1)\n            y[i] = category_id\n\n        return X, tf.keras.utils.to_categorical(y, num_classes=len(self.coco.cats))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:24.376523Z","iopub.execute_input":"2025-02-12T22:43:24.376805Z","iopub.status.idle":"2025-02-12T22:43:24.391683Z","shell.execute_reply.started":"2025-02-12T22:43:24.376782Z","shell.execute_reply":"2025-02-12T22:43:24.390708Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Image Parameters\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 16\nNUM_CLASSES = len(coco_train.cats)\n\n# Create Data Generators\ntrain_generator = CocoDataGenerator(coco_train, TRAIN_DIR, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\nval_generator = CocoDataGenerator(coco_val, VAL_DIR, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\ntrain_generator.image_ids = train_generator.image_ids[:1000]  # Use only 5000 images\nval_generator.image_ids = val_generator.image_ids[:100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:24.392592Z","iopub.execute_input":"2025-02-12T22:43:24.392891Z","iopub.status.idle":"2025-02-12T22:43:24.575696Z","shell.execute_reply.started":"2025-02-12T22:43:24.392863Z","shell.execute_reply":"2025-02-12T22:43:24.574893Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(f\"Total train images: {len(train_generator.image_ids)}\")\nprint(f\"Total val images: {len(val_generator.image_ids)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:24.576589Z","iopub.execute_input":"2025-02-12T22:43:24.576879Z","iopub.status.idle":"2025-02-12T22:43:24.593533Z","shell.execute_reply.started":"2025-02-12T22:43:24.576848Z","shell.execute_reply":"2025-02-12T22:43:24.592701Z"}},"outputs":[{"name":"stdout","text":"Total train images: 1000\nTotal val images: 100\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Image Parameters\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 16\nNUM_CLASSES = len(coco_train.cats)\n\n# Create Data Generators\ntrain_generator = CocoDataGenerator(coco_train, TRAIN_DIR, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\nval_generator = CocoDataGenerator(coco_val, VAL_DIR, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n\n# Load Pretrained MobileNetV2 (Optimized with alpha=0.35 for speed)\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3), alpha=0.35)\nbase_model.trainable = False  # Freeze base model\n\n# Add Custom Layers\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nout = Dense(NUM_CLASSES, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=out)\n\n# Compile Model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train Model with reduced epochs\nEPOCHS = 1\nhistory = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T22:43:24.594347Z","iopub.execute_input":"2025-02-12T22:43:24.594654Z","iopub.status.idle":"2025-02-12T23:11:12.284029Z","shell.execute_reply.started":"2025-02-12T22:43:24.594626Z","shell.execute_reply":"2025-02-12T23:11:12.283102Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_0.35_224_no_top.h5\n\u001b[1m2019640/2019640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3358/3358\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1663s\u001b[0m 491ms/step - accuracy: 0.4845 - loss: 2.1494 - val_accuracy: 0.0805 - val_loss: 10.6958\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Save Model\nmodel.save(\"mobilenetv2_rpc_optimized.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T23:11:12.285019Z","iopub.execute_input":"2025-02-12T23:11:12.285239Z","iopub.status.idle":"2025-02-12T23:11:12.562015Z","shell.execute_reply.started":"2025-02-12T23:11:12.285221Z","shell.execute_reply":"2025-02-12T23:11:12.561322Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Inference on Sample Image\ndef predict_image(image_path, model):\n    img = cv2.imread(image_path)\n    img = cv2.resize(img, IMG_SIZE)\n    img = img / 255.0\n    img = np.expand_dims(img, axis=0)\n    \n    predictions = model.predict(img)\n    predicted_class = np.argmax(predictions)\n    \n    plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n    plt.title(f\"Predicted Class: {predicted_class}\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T23:11:12.562783Z","iopub.execute_input":"2025-02-12T23:11:12.563024Z","iopub.status.idle":"2025-02-12T23:11:12.567756Z","shell.execute_reply.started":"2025-02-12T23:11:12.563001Z","shell.execute_reply":"2025-02-12T23:11:12.566776Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Initialize DeepSORT Tracker\ntracker = DeepSort(max_age=30, n_init=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T23:11:12.568423Z","iopub.execute_input":"2025-02-12T23:11:12.568637Z","iopub.status.idle":"2025-02-12T23:11:18.922193Z","shell.execute_reply.started":"2025-02-12T23:11:12.568618Z","shell.execute_reply":"2025-02-12T23:11:18.921514Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/deep_sort_realtime/embedder/embedder_pytorch.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.model.load_state_dict(torch.load(model_wts_path))\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import cv2\nfrom google.colab.patches import cv2_imshow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T23:11:18.923029Z","iopub.execute_input":"2025-02-12T23:11:18.923510Z","iopub.status.idle":"2025-02-12T23:11:18.943345Z","shell.execute_reply.started":"2025-02-12T23:11:18.923485Z","shell.execute_reply":"2025-02-12T23:11:18.942774Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Object Tracking Function\ndef track_objects(video_path, model):\n    cap = cv2.VideoCapture(video_path)\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        img_resized = cv2.resize(frame, IMG_SIZE) / 255.0\n        img_resized = np.expand_dims(img_resized, axis=0)\n        \n        predictions = model.predict(img_resized)\n        predicted_class = np.argmax(predictions)\n        \n        detections = [(50, 50, 200, 200, 0.9, predicted_class)]  # Mock detection\n        tracks = tracker.update_tracks(detections, frame=frame)\n        \n        for track in tracks:\n            if not track.is_confirmed():\n                continue\n            bbox = track.to_tlbr()\n            track_id = track.track_id\n            \n            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 255, 0), 2)\n            cv2.putText(frame, f'ID {track_id}', (int(bbox[0]), int(bbox[1]) - 10), \n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n        \n        cv2_imshow(frame)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    \n    cap.release()\n    cv2.destroyAllWindows()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T23:11:18.945273Z","iopub.execute_input":"2025-02-12T23:11:18.945502Z","iopub.status.idle":"2025-02-12T23:11:18.951813Z","shell.execute_reply.started":"2025-02-12T23:11:18.945482Z","shell.execute_reply":"2025-02-12T23:11:18.951180Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Run Tracking on Sample Video\nSAMPLE_VIDEO_PATH = \"/kaggle/input/samplevid\"\ntrack_objects(SAMPLE_VIDEO_PATH, model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-12T23:11:18.952764Z","iopub.execute_input":"2025-02-12T23:11:18.953038Z","iopub.status.idle":"2025-02-12T23:11:18.991570Z","shell.execute_reply.started":"2025-02-12T23:11:18.953012Z","shell.execute_reply":"2025-02-12T23:11:18.990777Z"}},"outputs":[],"execution_count":14}]}